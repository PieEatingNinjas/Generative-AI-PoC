# Resources

An attempt to gather some of the links and resources we have used while working on this project.

- [Tutorial: Explore Azure OpenAI Service embeddings and document search](https://learn.microsoft.com/en-us/azure/cognitive-services/openai/tutorials/embeddings)

    The page you provided is a tutorial on how to use OpenAI’s GPT-3 model with Azure Cognitive Services. It provides step-by-step instructions on how to create an Azure Cognitive Services account, create an OpenAI API key, install the OpenAI Python package, and use the OpenAI Python package to generate text using GPT-3.
- [ChatGPT Retrieval Plugin](https://github.com/openai/chatgpt-retrieval-plugin)

    The ChatGPT Retrieval Plugin repository provides a flexible solution for semantic search and retrieval of personal or organizational documents using natural language queries

- [Paul Graham GPT](https://github.com/mckaywrigley/paul-graham-gpt/tree/main)

    AI-powered search and chat for Paul Graham's essays.

- [Knowledge Retrieval Architecture for LLM’s (2023)](https://mattboegner.com/knowledge-retrieval-architecture-for-llms/)

    The page you provided is an article on knowledge retrieval architecture for LLMs. It discusses the importance of knowledge retrieval in LLMs, the challenges of knowledge retrieval in LLMs, a proposed architecture for knowledge retrieval in LLMs, and an evaluation of the proposed architecture.

- [Haystack](https://haystack.deepset.ai/tutorials/01_basic_qa_pipeline)

    Haystack is an open-source framework for building search systems that work intelligently over large document collections. Recent advances in NLP have enabled the application of question answering, retrieval and summarization to real world settings and Haystack is designed to be the bridge between research and industry.

- [LangChain](https://python.langchain.com/en/latest/index.html)

    A junger alternative for Haystack, more bleeding edge.
    
    LangChain is a framework for developing applications powered by language models. We believe that the most powerful and differentiated applications will not only call out to a language model via an API, but will also: Be data-aware: connect a language model to other sources of data, Be agentic: allow a language model to interact with its environment


- [Semantic Kernel](https://github.com/microsoft/semantic-kernel)

    [What is a vector Database](https://learn.microsoft.com/en-us/semantic-kernel/concepts-ai/vectordb)

    As I dislike python, and as I have not worked with it much the yak-shaving associated with it, I have been looking for a way to use these models though [ML.Net](https://dotnet.microsoft.com/en-us/apps/machinelearning-ai/ml-dotnet). This is just the result of a 5 minutes Google round but, might be nice venue for the future. [source](https://github.com/dotnet/machinelearning/issues/6600)

- [OpenAI Embeddings](https://platform.openai.com/docs/guides/embeddings/what-are-embeddings)

    A description of the OpenAI's intrerpretation of Embeddings

- [Video about how vector embeddings work](https://www.youtube.com/watch?v=lIoLCip0HwM)

    The [slides](https://github.com/tanchongmin/TensorFlow-Implementations/blob/main/Paper_Reviews/OpenAI%20Vector%20Embeddings.pdf)

- [How transformers work](http://jalammar.github.io/illustrated-transformer/)

- [Building LLM applications for production](https://huyenchip.com/2023/04/11/llm-engineering.html#part_3_promising_use_cases)

    The page you provided is an article on LLM engineering. It discusses the importance of LLM engineering, the challenges of LLM engineering, and promising use cases for LLMs.

- [How to customize LLMs like ChatGPT with your own data and documents](https://bdtechtalks.com/2023/05/01/customize-chatgpt-llm-embeddings/)

    The page you provided is an article on customizing ChatGPT LLM embeddings. It discusses the importance of LLM embeddings, the challenges of LLM embeddings, and how to customize ChatGPT LLM embeddings.

- [Vector database Faiss](https://learn.microsoft.com/en-us/semantic-kernel/concepts-ai/vectordb)